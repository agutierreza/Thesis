
% this file is called up by thesis.tex
% content in this file will be fed into the main document

\chapter{Contributions and future work} % top level followed by section, subsection
\label{chapter:Contributions}

% ----------------------- paths to graphics ------------------------

% change according to folder and file names
\ifpdf
    \graphicspath{{8/figures/PNG/}{8/figures/PDF/}{8/figures/}}
\else
    \graphicspath{{8/figures/EPS/}{8/figures/}}
\fi

% ----------------------- contents from here ------------------------

In this thesis, several computational issues related to the resolution of linear systems of equations
which come from the discretization of physical models described by
means of Partial Differential Equations (PDEs) have been discussed.
We start from the algebraic description of the model
associated with the physical phenomena and its contributions focus
on the design of techniques and computational models that allow the
resolution of these linear systems of equations. To be more specific, it deals with the study of models which require a high level of discretization
inn which the matrix $A$ involved in the system is usually very large and sparse (very low percentage of non-zero elements). One of the major contributions of this
thesis is the implementation of routines to solve sparse linear systems of
equations using High Performance Computing (HPC). More concretely, routines which require the exploitation
of Graphics Processing Units (GPUs) and multi-GPU clusters have been implemented.

%Chapter 2. SpMM.
In order to compute the Sparse Matrix
Matrix product (SpMM) on GPU platforms, a strategy called FastSpMM has been proposed. It has been evaluated and compared
to another algorithm described in literature, i.e., the CUSPARSE library (supplied by NVIDIA). Results have shown that FastSpMM
outperforms the existing approaches because it combines the use of the ELLPACK-R
storage format with the exploitation of the high ratio computation/memory access of
the SpMM operation and the overlapping of CPU-GPU communications/computations
by CUDA streaming computation. Future work in this research line will consist
of extending FastSpMM to matrices with complex elements,
broadening the kinds of platforms which can be exploited by FastSpMM. Moreover, we
are particularly interested in the reduction of the Processing Time through improving
the memory management. In order to achieve this goal, FastSpMM will be re-written
according to the GPU programming tool CudaDMA.
Additionally, the implementation of the multi-GPU version of FastSpMM is also a future line to work on.


%Chapter 3. JoS.
In addition, a BCG implementation to solve complex
and/or nonsymmetric linear systems of equations on GPUs has been carried out ($CuBCG_{ET}$).
After an extensive experimental evaluation using two sets of representative test matrices, it can be
concluded that $CuBCG_{ET}$ clearly achieves better performance that other approaches in the literature. This is mainly due to the fact that the
kernel ELLR-T can be better adapted to a wide variety of sparse matrix patterns. The analysis has shown that
 despite the fact that the inner products in the BCG algorithm represent a small percentage of the total workload, their poor
 performance on GPUs has a strong impact on the performance of the
BCG.

In this research line
a methodology has also been developed
for expressing every iteration  of BCG by the fusion of algebraic operations in single kernel (see Section~\ref{krylov}). Preliminary experimental evaluations of this methodology have shown the relevant improvements on the performance of BCG on GPUs \cite{JoS_Siham}. An extensive evaluation of this methodology applied to other Krylov methods (CG and BCGSTAB) will be part of future work.


%Chapter 4. Helmholtz
In this thesis a solver has also been developed
for the 3D Helmholtz
equation which combines the exploitation of the high regularity of
the matrices involved in the numerical methods, and the massive
parallelism supplied by heterogeneous architecture of modern
multi-GPU clusters. This parallel approach (called Fast-Helmholtz)
not only makes it possible to obtain a faster solution, but also to solve larger size instances.
According to this study's experimental results, several aspects
can still be  improved, so future
work will be focused on further optimizations. The difficulty of having the CPU and GPU workload well-balanced is an important part of our current and future research work. Our goal will consist of determining the automatic workload distribution among CPUs and GPUs.
 Furthermore, another future work will be focused on the
development of a hybrid version MPI-OpenMP on the heterogeneous multi-GPU cluster.
{\color{black}Apart from that, in order to increase the flexibility of the implementation, we also plan to use  rCUDA. This virtualization framework allows the execution of GPU-accelerated applications within virtual machines (VMs), enabling the sharing of a pool of centralized GPU resources that reside externally to the compute nodes.}

%improvements related to communication penalties will also be considered because of their strong relevance to the efficiency of applications running on multi-GPU clusters, i.e. the use of rCUDA interface.


Regarding the contribution of this thesis to the resolution of large and sparse linear systems of equation, there are several research issues that we believe are worth exploring in the future. One of them is the development of new strategies  for  the most widely used routines in the resolution of real problems. We plan to create an efficient open source library capable of improving the performance of other existing approaches. Moreover, we are interested in the performance evaluation  of some of these routines on many-core architectures such as the new GPU generations and Xeon Phi coprocessors.

%Chapter 5. Zaragoza.
The last chapter of this thesis has been focused on the resolution of a real physical problem of the
Optical Diffractional Tomography (ODT) based on holographic information. It allows the extraction of the shape of objects with high accuracy
and with a non-damaging technique. To be more specific, a three dimensional non-linear ODT model (named NLODT-P) to locate
particles, as part of a fluid velocimetry technique, has been implemented using MATLAB interface in combination with GPU devices.
Our implementation based on HPC has proven to be compulsory for the resolution of the 3D reconstruction based on  non-linear ODT problems.
With a long term perspective,  we plan to solve
real problems of HPIV
in aneurysms models where locating hundreds of particles will
be needed.

%Additionally, we plan to solve xxx.
%
%We also plan to xxx.


%Regarding the three dimensional non-linear ODT model, there are several research issues that we believe to be worth
%exploring in the future. One of them is xxx. Moreover, xxx.
%
%
%From the high performance computing perspective, there are many aspects that
%have not been sufficiently analyzed. In particular, we are interested in the projection
%of our proposed algorithms on heterogeneous environments.



% ---------------------------------------------------------------------------
%: ----------------------- end of thesis sub-document ------------------------
% ---------------------------------------------------------------------------










